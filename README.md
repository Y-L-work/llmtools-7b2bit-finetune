<h1 align="center"> llmtools-7b2bit-finetune: ä½ VRAM å¾®èª¿ LLaMA-7B</h1>

<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&height=200&section=header&text=llmtools-7b2bit-finetune&fontSize=50&animation=fadeIn" alt="llmtools-7b2bit-finetune Banner"/>
</p>

<p align="center">
<a href="https://github.com/Y-L-work/llmtools-7b2bit-finetune/stargazers">
  <img src="https://img.shields.io/github/stars/Y-L-work/llmtools-7b2bit-finetune?style=social" alt="Stars">
</a>
<a href="https://github.com/Y-L-work/llmtools-7b2bit-finetune/network/members">
  <img src="https://img.shields.io/github/forks/Y-L-work/llmtools-7b2bit-finetune?style=social" alt="Forks">
</a>
<a href="https://github.com/Y-L-work/llmtools-7b2bit-finetune/issues">
  <img src="https://img.shields.io/github/issues/Y-L-work/llmtools-7b2bit-finetune" alt="Issues">
</a>
<a href="https://github.com/Y-L-work/llmtools-7b2bit-finetune/blob/main/LICENSE">
  <img src="https://img.shields.io/github/license/Y-L-work/llmtools-7b2bit-finetune" alt="License">
</a>
</p>

---

## ğŸ“– å°ˆæ¡ˆç°¡ä»‹

 **llmtools-7b2bit-finetune** æ˜¯ä¸€å€‹ä½¿ç”¨ **LLMTools** åœ¨ **RTX 3050 Ti (4GB VRAM)** ä¸Š **å¾®èª¿ LLaMA-7B (2-bit é‡åŒ–)** çš„å°ˆæ¡ˆã€‚æœ¬å°ˆæ¡ˆçš„ç›®æ¨™æ˜¯é€é **2-bit LoRA å¾®èª¿**ï¼Œä½¿ **ä½éšé¡¯å¡ä¹Ÿèƒ½æœ‰æ•ˆåœ°é€²è¡Œ LLM å¾®èª¿**ï¼Œé¡¯è‘—é™ä½ VRAM éœ€æ±‚ã€‚

---

##  åŠŸèƒ½ç‰¹è‰²

- ğŸ”¹ **2-bit LoRA å¾®èª¿** â€” è®“ä½ VRAM è¨­å‚™èƒ½å¤ é«˜æ•ˆå¾®èª¿å¤§å‹èªè¨€æ¨¡å‹
- ğŸ”¹ **LLMTools é‡åŒ–æŠ€è¡“** â€” æä¾›é«˜æ•ˆèƒ½ã€ä½è¨˜æ†¶é«”æ¶ˆè€—çš„å¾®èª¿æ–¹å¼
- ğŸ”¹ **åŸºæ–¼ PyTorch 2.1.1 + CUDA 12.1** â€” å…¼å®¹æœ€æ–°çš„ GPU åŠ é€ŸæŠ€è¡“
- ğŸ”¹ **Hugging Face ä¸‹è¼‰èˆ‡ç®¡ç†** â€” æ”¯æ´ç†±é–€ LLaMA-7B æ¨¡å‹
- ğŸ”¹ **Docker å®¹å™¨åŒ–éƒ¨ç½²** â€” ç¢ºä¿ç’°å¢ƒä¸€è‡´æ€§

---

## ğŸ› ï¸ æŠ€è¡“æ¶æ§‹

**ä¸»è¦æŠ€è¡“èˆ‡å·¥å…·**

| é¡åˆ¥ | ğŸ› ï¸ å·¥å…· & æŠ€è¡“ |
|--------|----------------------|
| ğŸ§  **LLM å¾®èª¿** | ![LLMTools](https://img.shields.io/badge/LLMTools-2bit-blue?style=for-the-badge&logo=ai) ![LoRA](https://img.shields.io/badge/LoRA-Optimization-orange?style=for-the-badge) |
| ğŸ”¥ **æ·±åº¦å­¸ç¿’** | ![PyTorch](https://img.shields.io/badge/PyTorch-2.1.1-red?style=for-the-badge&logo=pytorch) ![CUDA](https://img.shields.io/badge/CUDA-12.1-green?style=for-the-badge) |
| ğŸ“š **æ¨¡å‹ä¸‹è¼‰** | ![HuggingFace](https://img.shields.io/badge/HuggingFace-FFD700?style=for-the-badge&logo=huggingface&logoColor=black) |
| ğŸš¢ **å®¹å™¨åŒ–éƒ¨ç½²** | ![Docker](https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white) |
| ğŸ“ **æ•¸æ“šé›†** | ![Alpaca](https://img.shields.io/badge/Alpaca-Dataset-lightblue?style=for-the-badge) |

---

## ğŸ“‚ å°ˆæ¡ˆç›®éŒ„

```plaintext
llmtools-7b2bit-finetune/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train.py             # ä¸»è¦å¾®èª¿è…³æœ¬
â”‚   â”œâ”€â”€ download_model.py    # ä¸‹è¼‰ 2-bit é‡åŒ–æ¨¡å‹
â”‚   â”œâ”€â”€ preprocess_data.py   # æ•¸æ“šé è™•ç†
â”‚   â”œâ”€â”€ config.py            # è¨­å®šå¾®èª¿åƒæ•¸
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ alpaca.json          # è¨“ç·´æ•¸æ“š
â”œâ”€â”€ output/                  # ä¿å­˜å¾®èª¿å¾Œçš„æ¨¡å‹
â”œâ”€â”€ requirements.txt         # ä¾è³´å®‰è£
â”œâ”€â”€ run.sh                   # å¿«é€Ÿé‹è¡Œè…³æœ¬
â”œâ”€â”€ Dockerfile               # Docker ç’°å¢ƒå®šç¾©
â”œâ”€â”€ docker-compose.yml       # Docker Compose è¨­å®š
â””â”€â”€ README.md                # æœ¬æ–‡ä»¶
```

---

##  å¿«é€Ÿé–‹å§‹

### 1ï¸âƒ£ å®‰è£ç’°å¢ƒ
```bash
conda create -n llmtools_env python=3.10 -y
conda activate llmtools_env
pip install -r requirements.txt
```

### 2ï¸âƒ£ ä¸‹è¼‰ LLaMA-7B 2-bit é‡åŒ–æ¨¡å‹
```bash
python src/download_model.py
```
> **æ³¨æ„**ï¼šé è¨­å­˜æ”¾ä½ç½®ç‚º `D:/huggingface_models/Llama_1_7b_E8P_2Bit/`

### 3ï¸âƒ£ é‹è¡Œå¾®èª¿

âœ… **æ–¹å¼ 1ï¼šç›´æ¥åŸ·è¡Œ Python è…³æœ¬**
```bash
python src/train.py
```

âœ… **æ–¹å¼ 2ï¼šä½¿ç”¨ Docker é‹è¡Œ**
```bash
docker-compose up --build
```

---

##  ç›®å‰å°ˆæ¡ˆé€²åº¦

âœ… **ç’°å¢ƒèˆ‡ä¾è³´å®‰è£**  
âœ… **ä¸‹è¼‰ LLaMA-7B 2-bit é‡åŒ–æ¨¡å‹**  
âœ… **æ•¸æ“šé è™•ç† (Alpaca Dataset)**  
âœ… **åŸºæœ¬å¾®èª¿è…³æœ¬ (`train.py`) å»ºç«‹**  
â³ **æ¸¬è©¦ 2-bit å¾®èª¿éç¨‹**  
â³ **æ¨¡å‹è¨“ç·´èˆ‡æ•ˆæœé©—è­‰**  
â³ **å¾®èª¿å¾Œæ¨¡å‹çš„æ¨ç†æ¸¬è©¦**  

**è¨ˆç•«ä¸­çš„æ”¹é€²æ–¹å‘ï¼š**
- ğŸ”¹ **èª¿æ•´ LoRA è¶…åƒæ•¸ï¼Œå„ªåŒ–å¾®èª¿æ•ˆæœ**
- ğŸ”¹ **æ¢ç´¢æœ€ä½³ 2-bit é‡åŒ–ç­–ç•¥ä»¥é™ä½ VRAM ä½¿ç”¨é‡**
- ğŸ”¹ **å¢åŠ  TensorRT åŠ é€Ÿæ¨ç†ï¼Œæå‡åŸ·è¡Œæ•ˆèƒ½**

---

## ğŸ“Š GitHub æ´»å‹•

![GitHub Activity](https://github-readme-activity-graph.vercel.app/graph?username=Y-L-work&theme=react-dark)

---

<p align="center">
  **å¦‚æœä½ å–œæ­¡é€™å€‹å°ˆæ¡ˆï¼Œè«‹è¨˜å¾—çµ¦å€‹ â­ æ”¯æŒï¼**
</p>
